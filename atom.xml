<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[王科的博客]]></title>
  <link href="http://wangke.pw/atom.xml" rel="self"/>
  <link href="http://wangke.pw/"/>
  <updated>2016-01-04T11:45:32+08:00</updated>
  <id>http://wangke.pw/</id>
  <author>
    <name><![CDATA[]]></name>
    
  </author>
  <generator uri="http://www.mweb.im/">MWeb</generator>
  
  <entry>
    <title type="html"><![CDATA[centos7 安装与配置 redis]]></title>
    <link href="http://wangke.pw/52.html"/>
    <updated>2016-01-04T11:36:52+08:00</updated>
    <id>http://wangke.pw/52.html</id>
    <content type="html"><![CDATA[
<h3 id="toc_0">一、安装</h3>

<p>命令<code>yum install redis</code>安装很方便</p>

<h3 id="toc_1">二、初始化常用配置</h3>

<p>yum安装后默认配置文件在<code>/etc/redis.conf</code></p>

<p>使用daemon方式运行程序，默认为非daemon方式运行<br/>
<code>daemonize yes</code></p>

<p>为了速度我挂载了固态硬盘来为redis做持久化，所以要配置下持久化的路径<br/>
<code>dbfilename dump.rdb</code> #SNAPSHOTTING的文件名<br/>
<code>dir /opt/data/redis/</code> #SNAPSHOTTING文件的路径</p>

<p>设置为警告日志记录，减少日质量<br/>
<code>loglevel warning</code></p>

<p>注释掉本地IP绑定，开启外网访问<br/>
<code># bind 127.0.0.1</code></p>

<p>添加requirepass设置连接密码<br/>
<code>requirepass ***（你的密码）</code></p>

<h3 id="toc_2">三、编写启动脚本</h3>

<p>输入命令<br/>
<code>vim /etc/init.d/redis</code><br/>
脚本代码：<br/>
```shell<br/>
#chkconfig: 2345 10 90<br/>
#description: Start and Stop redis<br/>
PATH=/usr/local/bin:/sbin:/usr/bin:/bin #根据你的本机情况设定</p>

<p>REDISPORT=6379<br/>
EXEC=/usr/local/bin/redis-server #根据你的本机情况设定<br/>
REDIS_CLI=/usr/local/bin/redis-cli #根据你的本机情况设定</p>

<p>PIDFILE=/var/run/redis.pid #根据你的本机情况设定（这里要和redis.conf设置一致）<br/>
CONF=<q>/etc/redis.conf</q> #根据你的本机情况设定</p>

<p>case <q>$1</q> in<br/>
start)<br/>
if [ -f \(PIDFILE ]<br/>
then<br/>
echo &quot;\)PIDFILE exists, process is already running or crashed<q><br/>
else<br/>
echo</q>Starting Redis server...<q><br/>
\(EXEC \)CONF<br/>
fi<br/>
if [</q>\(?&quot;=&quot;0&quot; ]<br/>
then<br/>
echo &quot;Redis is running...&quot;<br/>
fi<br/>
;;<br/>
stop)<br/>
if [ ! -f \)PIDFILE ]<br/>
then<br/>
echo <q>$PIDFILE does not exist, process is not running</q><br/>
else<br/>
PID=$(cat \(PIDFILE)<br/>
echo &quot;Stopping ...&quot;<br/>
\$REDIS_CLI -p \)REDISPORT SHUTDOWN<br/>
while [ -x \({PIDFILE} ]<br/>
do<br/>
echo &quot;Waiting for Redis to shutdown ...&quot;<br/>
sleep 1<br/>
done<br/>
echo &quot;Redis stopped&quot;<br/>
fi<br/>
;;<br/>
restart|force-reload)<br/>
\){0} stop<br/>
${0} start<br/>
;;<br/>
*)<br/>
echo <q>Usage: /etc/init.d/redis {start|stop|restart|force-reload}</q> &gt;&amp;2<br/>
exit 1<br/>
esac<br/>
``<code><br/>
给启动脚本设定权限<br/>
</code>chmod +x /etc/init.d/redis`</p>

<p>设置开机启动服务(centos 6.5)<br/>
<code>sudo chkconfig redis on</code></p>

<p>设置开机启动服务(centos 7)<br/>
<code>vim /etc/rc.d/rc.local</code></p>

<p>设置权限否则不会生效<br/>
<code>chmod +x /etc/rc.d/rc.local</code></p>

<h3 id="toc_3">到这里就配置完成了</h3>

<p>启动服务：<br/>
<code>service redis start</code></p>

<p>停止服务：<br/>
<code>service redis stop</code></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Python实现分布式爬虫]]></title>
    <link href="http://wangke.pw/41.html"/>
    <updated>2016-01-04T11:29:31+08:00</updated>
    <id>http://wangke.pw/41.html</id>
    <content type="html"><![CDATA[
<p>最近在做一个项目，涉及到几亿数据的采集和分析，单机采集在内存和宽带遇到了瓶颈，所以尝试实现分布式采集。本文仅做一个简单的分布式采集demo，主要是讲讲实现思路和用到的技术要点。</p>

<p>分布式采集实现的目标是有一台master服务器负责分派及跟踪任务，而worker客户机则可以是若干台，随着业务量的增长可以弹性扩充。（也可以称为master-slave模式）</p>

<h3 id="toc_0">使用Python实现分布式爬虫所依赖到的包如下：</h3>

<ul>
<li>multiprocessing.managers：进程管理，并可以把进程分布到网络中，实现分布式的核心组件</li>
<li>Queue：线程安全的队列，用于任务分派和任务跟踪</li>
<li>threading：多线程操作</li>
<li>requests：http请求库，API简单，比较好用</li>
</ul>

<h3 id="toc_1">master服务器代码：</h3>

<pre><code class="language-python"># -*- coding: utf-8 -*-
__author__ = &#39;Colin&#39;
 
import Queue, time, threading
from multiprocessing.managers import BaseManager
 
class SpiderManager(BaseManager):
    pass
 
# 任务分布队列 （工作机获取任务队列的网址进行爬取）
task_queue = Queue.Queue()
# 结果接受队列
result_queue = Queue.Queue()
 
# 将两个队列注册到网络
SpiderManager.register(&#39;task_queue&#39;, callable=lambda: task_queue)
SpiderManager.register(&#39;result_queue&#39;, callable=lambda: result_queue)
 
# 设定服务器信息
manager = SpiderManager(address=(&#39;127.0.0.1&#39;, 3838), authkey=&#39;hellokey&#39;)
# 启动服务器
manager.start()
# 获取网络上的任务队列
task = manager.task_queue()
result = manager.result_queue()
 
# 预设运行信息
start_time = time.time()
spider_count = 0
 
# 模拟分配任务，每间隔10秒分配100条网址给工作机
def allot_work(task):
    while True:
        x = range(100)
        for i in x:
            task.put(&#39;http://www.baidu.com/&#39;)
        print &#39;任务分配成功，当前任务数：&#39;, task.qsize()
        # 每间隔1秒分配一次任务
        time.sleep(3)
 
# 获取工作机任务执行结果
def get_result(result, start_time, spider_count):
    while True:
        if result.empty() == False:
            r = result.get(timeout=3)
            spider_count += 1
            print &#39;{0} 耗时{1} 执行了{2}次爬虫任务&#39;.format(r, time.time() - start_time, spider_count)
        else:
            # 如果没有执行结果，休息5秒钟
            time.sleep(5)
 
print &#39;开始执行任务分配……&#39;
# 启动任务分配线程
threading.Thread(target=allot_work, args=(task,)).start()
 
print &#39;开始接收任务执行结果……&#39;
# 启动任务结果接收线程
threading.Thread(target=get_result, args=(result, start_time, spider_count)).start()
</code></pre>

<h3 id="toc_2">worker客户机代码：</h3>

<pre><code class="language-python"># -*- coding: utf-8 -*-
__author__ = &#39;Colin&#39;
 
import time, Queue, requests, threading, uuid
from multiprocessing.managers import BaseManager
 
# 创建和服务器一致的SpiderManager
class SpiderManager(BaseManager):
    pass
 
# 模拟一个唯一的机器名字用于服务器区分
host = uuid.uuid4()
 
# 客户端只需要通过名字注册网络上的Queue
SpiderManager.register(&#39;task_queue&#39;)
SpiderManager.register(&#39;result_queue&#39;)
 
# 配置服务器信息，和服务器配置保持一致
server_addr = (&#39;127.0.0.1&#39;, 3838)
manager = SpiderManager(address=server_addr, authkey=&#39;hellokey&#39;)
 
# 连接服务器
manager.connect()
print &#39;服务器连接成功……&#39;
 
# 获取网络上的队列对象
task = manager.task_queue()
result = manager.result_queue()
 
# 执行任务，并把任务执行结果返回给服务器
def do_work(task, result):
    while True:
        try:
            if task.empty() == False:
                # 获取任务
                url = task.get()
                print &#39;获取任务成功，当前任务数：&#39;,task.qsize()
                # 爬取网页
                html = requests.get(url)
                # 将执行结果返回给服务器
                r_str = &#39;host:{0} &amp; status_code:{1}&#39;.format(host, html.status_code)
                print r_str
                result.put(r_str)
            else:
                # 如果没有接受到任务则休眠5秒
                time.sleep(5)
        except Exception as e:
            r_str = &#39;host:{0} &amp; error:{1}&#39;.format(host, e.message)
            print(r_str)
            result.put(r_str)
 
print &#39;开始执行任务……&#39;
threading.Thread(target=do_work, args=(task, result)).start()
</code></pre>

<p>到这里一个简易的分布式爬虫系统就实现了，一台服务器运行manager.py，N台服务器运行worker.py即可，每启动一台worker会自动注册到manager，也就可以弹性扩展了。根据我本机测试，10台worker每秒请求量可达26次（这里是有宽带瓶颈的），需要提高请求量只需要增加更多的worker客户机。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[关于王科]]></title>
    <link href="http://wangke.pw/about.html"/>
    <updated>2016-01-04T09:43:17+08:00</updated>
    <id>http://wangke.pw/about.html</id>
    <content type="html"><![CDATA[
<p><center><br/>
<img src="media/14518717975689/14518772524638.jpg" alt="“王科的照片”"/><br/>
</center></p>

<p>王科，国内首批O2O实践者、O2O解决方案专家。擅长SEO、网络推广、网络营销、软件开发。从事过个人站长、创业做过电商、自学编程并成立了专业的SEO软件开发公司。同时是国内最早一批研究微信应用开发和微信营销的实战者。</p>

<h3 id="toc_0">个人经历：</h3>

<ul>
<li><p>2005～2007年，从事个人站长，将QQ空间（日搜索量20万+）关键词优化到百度第一，投入了大量资金购买友情链接，后来被众多SEOer研究分析SEO的方法，最终催生了友情链接买卖市场，友情链接买卖年交易额高达数亿元。</p></li>
<li><p>2008～2010年，首次创业成立福州鼎盛网络科技有限公司，从事电子商务，积累了丰富的网络推广经验，如sem、edm、微博营销、软文营销等。</p></li>
<li><p>2010～2011年，基于个人丰富的SEO经验同时自学编程，独自研发了SEO神器《黑马博客群发》，该神器拥有16万免费会员，2万商业会员。与《虫虫博客群发》、《侠客站群》齐名，业内称为外链三剑客。</p></li>
<li><p>2011～2013年，成立专业SEO软件公司——重庆朝飞科技有限公司，并带领团队研发了《网赢发布平台》、《SEO优化王》两款顶级的SEO软件。迄今为止SEO优化王仍是全球最智能的SEO软件。</p></li>
<li><p>2014~至今，痴迷Python编程、大数据挖掘、大流量网站运营。</p></li>
</ul>

<p>本着分享、开放、借势、共赢的互联网精神，希望通过个人博客结交各个领域的朋友，共话理想，共谋发展。期待您的莅临，与您真诚的交流和分享：<br/>
<center><br/>
<img src="media/14518717975689/14518776410087.jpg" alt=""/><br/>
<em>微信扫一扫，加王科为好友</em></p>

<blockquote>
<p>微信/QQ：919695<br/>
邮箱：wangke{#}weixin.net 请将{#}替换为@<br/>
<center/></p>
</blockquote>

]]></content>
  </entry>
  
</feed>
